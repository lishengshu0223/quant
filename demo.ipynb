{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692212\n",
      "[2]\tvalid_0's binary_logloss: 0.691413\n",
      "[3]\tvalid_0's binary_logloss: 0.690714\n",
      "[4]\tvalid_0's binary_logloss: 0.690093\n",
      "[5]\tvalid_0's binary_logloss: 0.689514\n",
      "[6]\tvalid_0's binary_logloss: 0.689026\n",
      "[7]\tvalid_0's binary_logloss: 0.688583\n",
      "[8]\tvalid_0's binary_logloss: 0.688161\n",
      "[9]\tvalid_0's binary_logloss: 0.687747\n",
      "[10]\tvalid_0's binary_logloss: 0.687394\n",
      "[11]\tvalid_0's binary_logloss: 0.687071\n",
      "[12]\tvalid_0's binary_logloss: 0.686805\n",
      "[13]\tvalid_0's binary_logloss: 0.68653\n",
      "[14]\tvalid_0's binary_logloss: 0.68624\n",
      "[15]\tvalid_0's binary_logloss: 0.685953\n",
      "[16]\tvalid_0's binary_logloss: 0.685729\n",
      "[17]\tvalid_0's binary_logloss: 0.685515\n",
      "[18]\tvalid_0's binary_logloss: 0.685298\n",
      "[19]\tvalid_0's binary_logloss: 0.68507\n",
      "[20]\tvalid_0's binary_logloss: 0.684866\n",
      "[21]\tvalid_0's binary_logloss: 0.684666\n",
      "[22]\tvalid_0's binary_logloss: 0.684483\n",
      "[23]\tvalid_0's binary_logloss: 0.684294\n",
      "[24]\tvalid_0's binary_logloss: 0.684084\n",
      "[25]\tvalid_0's binary_logloss: 0.683921\n",
      "[26]\tvalid_0's binary_logloss: 0.683759\n",
      "[27]\tvalid_0's binary_logloss: 0.683595\n",
      "[28]\tvalid_0's binary_logloss: 0.683426\n",
      "[29]\tvalid_0's binary_logloss: 0.683286\n",
      "[30]\tvalid_0's binary_logloss: 0.683054\n",
      "[31]\tvalid_0's binary_logloss: 0.682869\n",
      "[32]\tvalid_0's binary_logloss: 0.682705\n",
      "[33]\tvalid_0's binary_logloss: 0.682585\n",
      "[34]\tvalid_0's binary_logloss: 0.682456\n",
      "[35]\tvalid_0's binary_logloss: 0.68231\n",
      "[36]\tvalid_0's binary_logloss: 0.682178\n",
      "[37]\tvalid_0's binary_logloss: 0.682023\n",
      "[38]\tvalid_0's binary_logloss: 0.681907\n",
      "[39]\tvalid_0's binary_logloss: 0.681779\n",
      "[40]\tvalid_0's binary_logloss: 0.681662\n",
      "[41]\tvalid_0's binary_logloss: 0.681518\n",
      "[42]\tvalid_0's binary_logloss: 0.681392\n",
      "[43]\tvalid_0's binary_logloss: 0.681271\n",
      "[44]\tvalid_0's binary_logloss: 0.681158\n",
      "[45]\tvalid_0's binary_logloss: 0.681034\n",
      "[46]\tvalid_0's binary_logloss: 0.68092\n",
      "[47]\tvalid_0's binary_logloss: 0.680779\n",
      "[48]\tvalid_0's binary_logloss: 0.680669\n",
      "[49]\tvalid_0's binary_logloss: 0.680564\n",
      "[50]\tvalid_0's binary_logloss: 0.680459\n",
      "[51]\tvalid_0's binary_logloss: 0.680335\n",
      "[52]\tvalid_0's binary_logloss: 0.680249\n",
      "[53]\tvalid_0's binary_logloss: 0.680146\n",
      "[54]\tvalid_0's binary_logloss: 0.68003\n",
      "[55]\tvalid_0's binary_logloss: 0.679916\n",
      "[56]\tvalid_0's binary_logloss: 0.679818\n",
      "[57]\tvalid_0's binary_logloss: 0.679731\n",
      "[58]\tvalid_0's binary_logloss: 0.679638\n",
      "[59]\tvalid_0's binary_logloss: 0.679518\n",
      "[60]\tvalid_0's binary_logloss: 0.67939\n",
      "[61]\tvalid_0's binary_logloss: 0.679296\n",
      "[62]\tvalid_0's binary_logloss: 0.679178\n",
      "[63]\tvalid_0's binary_logloss: 0.679083\n",
      "[64]\tvalid_0's binary_logloss: 0.678979\n",
      "[65]\tvalid_0's binary_logloss: 0.67887\n",
      "[66]\tvalid_0's binary_logloss: 0.678768\n",
      "[67]\tvalid_0's binary_logloss: 0.678689\n",
      "[68]\tvalid_0's binary_logloss: 0.67858\n",
      "[69]\tvalid_0's binary_logloss: 0.678501\n",
      "[70]\tvalid_0's binary_logloss: 0.678425\n",
      "[71]\tvalid_0's binary_logloss: 0.678336\n",
      "[72]\tvalid_0's binary_logloss: 0.678257\n",
      "[73]\tvalid_0's binary_logloss: 0.678186\n",
      "[74]\tvalid_0's binary_logloss: 0.678112\n",
      "[75]\tvalid_0's binary_logloss: 0.678035\n",
      "[76]\tvalid_0's binary_logloss: 0.677953\n",
      "[77]\tvalid_0's binary_logloss: 0.677859\n",
      "[78]\tvalid_0's binary_logloss: 0.677779\n",
      "[79]\tvalid_0's binary_logloss: 0.677698\n",
      "[80]\tvalid_0's binary_logloss: 0.677616\n",
      "[81]\tvalid_0's binary_logloss: 0.677552\n",
      "[82]\tvalid_0's binary_logloss: 0.677497\n",
      "[83]\tvalid_0's binary_logloss: 0.677403\n",
      "[84]\tvalid_0's binary_logloss: 0.67733\n",
      "[85]\tvalid_0's binary_logloss: 0.677247\n",
      "[86]\tvalid_0's binary_logloss: 0.677169\n",
      "[87]\tvalid_0's binary_logloss: 0.677079\n",
      "[88]\tvalid_0's binary_logloss: 0.677002\n",
      "[89]\tvalid_0's binary_logloss: 0.676921\n",
      "[90]\tvalid_0's binary_logloss: 0.676866\n",
      "[91]\tvalid_0's binary_logloss: 0.676809\n",
      "[92]\tvalid_0's binary_logloss: 0.676734\n",
      "[93]\tvalid_0's binary_logloss: 0.676645\n",
      "[94]\tvalid_0's binary_logloss: 0.67657\n",
      "[95]\tvalid_0's binary_logloss: 0.676485\n",
      "[96]\tvalid_0's binary_logloss: 0.676415\n",
      "[97]\tvalid_0's binary_logloss: 0.67633\n",
      "[98]\tvalid_0's binary_logloss: 0.676273\n",
      "[99]\tvalid_0's binary_logloss: 0.676185\n",
      "[100]\tvalid_0's binary_logloss: 0.676119\n",
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692347\n",
      "[2]\tvalid_0's binary_logloss: 0.691654\n",
      "[3]\tvalid_0's binary_logloss: 0.691063\n",
      "[4]\tvalid_0's binary_logloss: 0.690529\n",
      "[5]\tvalid_0's binary_logloss: 0.690048\n",
      "[6]\tvalid_0's binary_logloss: 0.689593\n",
      "[7]\tvalid_0's binary_logloss: 0.689209\n",
      "[8]\tvalid_0's binary_logloss: 0.68885\n",
      "[9]\tvalid_0's binary_logloss: 0.68852\n",
      "[10]\tvalid_0's binary_logloss: 0.688217\n",
      "[11]\tvalid_0's binary_logloss: 0.687914\n",
      "[12]\tvalid_0's binary_logloss: 0.68767\n",
      "[13]\tvalid_0's binary_logloss: 0.687422\n",
      "[14]\tvalid_0's binary_logloss: 0.687173\n",
      "[15]\tvalid_0's binary_logloss: 0.686931\n",
      "[16]\tvalid_0's binary_logloss: 0.686699\n",
      "[17]\tvalid_0's binary_logloss: 0.686499\n",
      "[18]\tvalid_0's binary_logloss: 0.686267\n",
      "[19]\tvalid_0's binary_logloss: 0.686064\n",
      "[20]\tvalid_0's binary_logloss: 0.685874\n",
      "[21]\tvalid_0's binary_logloss: 0.685695\n",
      "[22]\tvalid_0's binary_logloss: 0.685498\n",
      "[23]\tvalid_0's binary_logloss: 0.685335\n",
      "[24]\tvalid_0's binary_logloss: 0.685155\n",
      "[25]\tvalid_0's binary_logloss: 0.684962\n",
      "[26]\tvalid_0's binary_logloss: 0.684792\n",
      "[27]\tvalid_0's binary_logloss: 0.684639\n",
      "[28]\tvalid_0's binary_logloss: 0.684499\n",
      "[29]\tvalid_0's binary_logloss: 0.684369\n",
      "[30]\tvalid_0's binary_logloss: 0.684215\n",
      "[31]\tvalid_0's binary_logloss: 0.684044\n",
      "[32]\tvalid_0's binary_logloss: 0.683917\n",
      "[33]\tvalid_0's binary_logloss: 0.683757\n",
      "[34]\tvalid_0's binary_logloss: 0.683639\n",
      "[35]\tvalid_0's binary_logloss: 0.683526\n",
      "[36]\tvalid_0's binary_logloss: 0.683381\n",
      "[37]\tvalid_0's binary_logloss: 0.683257\n",
      "[38]\tvalid_0's binary_logloss: 0.683123\n",
      "[39]\tvalid_0's binary_logloss: 0.682998\n",
      "[40]\tvalid_0's binary_logloss: 0.682877\n",
      "[41]\tvalid_0's binary_logloss: 0.682736\n",
      "[42]\tvalid_0's binary_logloss: 0.682626\n",
      "[43]\tvalid_0's binary_logloss: 0.68249\n",
      "[44]\tvalid_0's binary_logloss: 0.682369\n",
      "[45]\tvalid_0's binary_logloss: 0.682277\n",
      "[46]\tvalid_0's binary_logloss: 0.682152\n",
      "[47]\tvalid_0's binary_logloss: 0.682066\n",
      "[48]\tvalid_0's binary_logloss: 0.681926\n",
      "[49]\tvalid_0's binary_logloss: 0.681813\n",
      "[50]\tvalid_0's binary_logloss: 0.681711\n",
      "[51]\tvalid_0's binary_logloss: 0.681578\n",
      "[52]\tvalid_0's binary_logloss: 0.681462\n",
      "[53]\tvalid_0's binary_logloss: 0.681377\n",
      "[54]\tvalid_0's binary_logloss: 0.681272\n",
      "[55]\tvalid_0's binary_logloss: 0.681158\n",
      "[56]\tvalid_0's binary_logloss: 0.68108\n",
      "[57]\tvalid_0's binary_logloss: 0.681004\n",
      "[58]\tvalid_0's binary_logloss: 0.680898\n",
      "[59]\tvalid_0's binary_logloss: 0.680802\n",
      "[60]\tvalid_0's binary_logloss: 0.680712\n",
      "[61]\tvalid_0's binary_logloss: 0.68064\n",
      "[62]\tvalid_0's binary_logloss: 0.680568\n",
      "[63]\tvalid_0's binary_logloss: 0.680454\n",
      "[64]\tvalid_0's binary_logloss: 0.680386\n",
      "[65]\tvalid_0's binary_logloss: 0.680302\n",
      "[66]\tvalid_0's binary_logloss: 0.680228\n",
      "[67]\tvalid_0's binary_logloss: 0.68013\n",
      "[68]\tvalid_0's binary_logloss: 0.680012\n",
      "[69]\tvalid_0's binary_logloss: 0.679919\n",
      "[70]\tvalid_0's binary_logloss: 0.67982\n",
      "[71]\tvalid_0's binary_logloss: 0.679733\n",
      "[72]\tvalid_0's binary_logloss: 0.679662\n",
      "[73]\tvalid_0's binary_logloss: 0.6796\n",
      "[74]\tvalid_0's binary_logloss: 0.679515\n",
      "[75]\tvalid_0's binary_logloss: 0.679431\n",
      "[76]\tvalid_0's binary_logloss: 0.679343\n",
      "[77]\tvalid_0's binary_logloss: 0.679293\n",
      "[78]\tvalid_0's binary_logloss: 0.679204\n",
      "[79]\tvalid_0's binary_logloss: 0.679119\n",
      "[80]\tvalid_0's binary_logloss: 0.679074\n",
      "[81]\tvalid_0's binary_logloss: 0.679005\n",
      "[82]\tvalid_0's binary_logloss: 0.678925\n",
      "[83]\tvalid_0's binary_logloss: 0.678846\n",
      "[84]\tvalid_0's binary_logloss: 0.678781\n",
      "[85]\tvalid_0's binary_logloss: 0.678714\n",
      "[86]\tvalid_0's binary_logloss: 0.678639\n",
      "[87]\tvalid_0's binary_logloss: 0.678563\n",
      "[88]\tvalid_0's binary_logloss: 0.678481\n",
      "[89]\tvalid_0's binary_logloss: 0.678421\n",
      "[90]\tvalid_0's binary_logloss: 0.678345\n",
      "[91]\tvalid_0's binary_logloss: 0.678289\n",
      "[92]\tvalid_0's binary_logloss: 0.678215\n",
      "[93]\tvalid_0's binary_logloss: 0.678148\n",
      "[94]\tvalid_0's binary_logloss: 0.67808\n",
      "[95]\tvalid_0's binary_logloss: 0.678006\n",
      "[96]\tvalid_0's binary_logloss: 0.677924\n",
      "[97]\tvalid_0's binary_logloss: 0.677858\n",
      "[98]\tvalid_0's binary_logloss: 0.6778\n",
      "[99]\tvalid_0's binary_logloss: 0.677749\n",
      "[100]\tvalid_0's binary_logloss: 0.677693\n",
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692284\n",
      "[2]\tvalid_0's binary_logloss: 0.691558\n",
      "[3]\tvalid_0's binary_logloss: 0.690929\n",
      "[4]\tvalid_0's binary_logloss: 0.690382\n",
      "[5]\tvalid_0's binary_logloss: 0.689901\n",
      "[6]\tvalid_0's binary_logloss: 0.689479\n",
      "[7]\tvalid_0's binary_logloss: 0.689076\n",
      "[8]\tvalid_0's binary_logloss: 0.688732\n",
      "[9]\tvalid_0's binary_logloss: 0.688403\n",
      "[10]\tvalid_0's binary_logloss: 0.688111\n",
      "[11]\tvalid_0's binary_logloss: 0.687839\n",
      "[12]\tvalid_0's binary_logloss: 0.687598\n",
      "[13]\tvalid_0's binary_logloss: 0.687371\n",
      "[14]\tvalid_0's binary_logloss: 0.687137\n",
      "[15]\tvalid_0's binary_logloss: 0.686956\n",
      "[16]\tvalid_0's binary_logloss: 0.686741\n",
      "[17]\tvalid_0's binary_logloss: 0.686593\n",
      "[18]\tvalid_0's binary_logloss: 0.686406\n",
      "[19]\tvalid_0's binary_logloss: 0.686253\n",
      "[20]\tvalid_0's binary_logloss: 0.68611\n",
      "[21]\tvalid_0's binary_logloss: 0.685954\n",
      "[22]\tvalid_0's binary_logloss: 0.685818\n",
      "[23]\tvalid_0's binary_logloss: 0.685678\n",
      "[24]\tvalid_0's binary_logloss: 0.685529\n",
      "[25]\tvalid_0's binary_logloss: 0.685392\n",
      "[26]\tvalid_0's binary_logloss: 0.685266\n",
      "[27]\tvalid_0's binary_logloss: 0.685132\n",
      "[28]\tvalid_0's binary_logloss: 0.684985\n",
      "[29]\tvalid_0's binary_logloss: 0.68487\n",
      "[30]\tvalid_0's binary_logloss: 0.684763\n",
      "[31]\tvalid_0's binary_logloss: 0.68466\n",
      "[32]\tvalid_0's binary_logloss: 0.684563\n",
      "[33]\tvalid_0's binary_logloss: 0.684472\n",
      "[34]\tvalid_0's binary_logloss: 0.684357\n",
      "[35]\tvalid_0's binary_logloss: 0.684248\n",
      "[36]\tvalid_0's binary_logloss: 0.684166\n",
      "[37]\tvalid_0's binary_logloss: 0.68408\n",
      "[38]\tvalid_0's binary_logloss: 0.683967\n",
      "[39]\tvalid_0's binary_logloss: 0.683875\n",
      "[40]\tvalid_0's binary_logloss: 0.683781\n",
      "[41]\tvalid_0's binary_logloss: 0.683662\n",
      "[42]\tvalid_0's binary_logloss: 0.683571\n",
      "[43]\tvalid_0's binary_logloss: 0.68348\n",
      "[44]\tvalid_0's binary_logloss: 0.683379\n",
      "[45]\tvalid_0's binary_logloss: 0.683307\n",
      "[46]\tvalid_0's binary_logloss: 0.683212\n",
      "[47]\tvalid_0's binary_logloss: 0.683127\n",
      "[48]\tvalid_0's binary_logloss: 0.683048\n",
      "[49]\tvalid_0's binary_logloss: 0.682988\n",
      "[50]\tvalid_0's binary_logloss: 0.682898\n",
      "[51]\tvalid_0's binary_logloss: 0.682809\n",
      "[52]\tvalid_0's binary_logloss: 0.682724\n",
      "[53]\tvalid_0's binary_logloss: 0.682652\n",
      "[54]\tvalid_0's binary_logloss: 0.682564\n",
      "[55]\tvalid_0's binary_logloss: 0.682453\n",
      "[56]\tvalid_0's binary_logloss: 0.682387\n",
      "[57]\tvalid_0's binary_logloss: 0.682289\n",
      "[58]\tvalid_0's binary_logloss: 0.682211\n",
      "[59]\tvalid_0's binary_logloss: 0.682129\n",
      "[60]\tvalid_0's binary_logloss: 0.682051\n",
      "[61]\tvalid_0's binary_logloss: 0.681969\n",
      "[62]\tvalid_0's binary_logloss: 0.681899\n",
      "[63]\tvalid_0's binary_logloss: 0.681825\n",
      "[64]\tvalid_0's binary_logloss: 0.681732\n",
      "[65]\tvalid_0's binary_logloss: 0.681661\n",
      "[66]\tvalid_0's binary_logloss: 0.681601\n",
      "[67]\tvalid_0's binary_logloss: 0.681519\n",
      "[68]\tvalid_0's binary_logloss: 0.681466\n",
      "[69]\tvalid_0's binary_logloss: 0.681414\n",
      "[70]\tvalid_0's binary_logloss: 0.681344\n",
      "[71]\tvalid_0's binary_logloss: 0.681271\n",
      "[72]\tvalid_0's binary_logloss: 0.681215\n",
      "[73]\tvalid_0's binary_logloss: 0.681152\n",
      "[74]\tvalid_0's binary_logloss: 0.68109\n",
      "[75]\tvalid_0's binary_logloss: 0.681029\n",
      "[76]\tvalid_0's binary_logloss: 0.680965\n",
      "[77]\tvalid_0's binary_logloss: 0.680898\n",
      "[78]\tvalid_0's binary_logloss: 0.680834\n",
      "[79]\tvalid_0's binary_logloss: 0.680775\n",
      "[80]\tvalid_0's binary_logloss: 0.680687\n",
      "[81]\tvalid_0's binary_logloss: 0.680633\n",
      "[82]\tvalid_0's binary_logloss: 0.680566\n",
      "[83]\tvalid_0's binary_logloss: 0.680511\n",
      "[84]\tvalid_0's binary_logloss: 0.680432\n",
      "[85]\tvalid_0's binary_logloss: 0.680366\n",
      "[86]\tvalid_0's binary_logloss: 0.680312\n",
      "[87]\tvalid_0's binary_logloss: 0.680255\n",
      "[88]\tvalid_0's binary_logloss: 0.680203\n",
      "[89]\tvalid_0's binary_logloss: 0.680135\n",
      "[90]\tvalid_0's binary_logloss: 0.680092\n",
      "[91]\tvalid_0's binary_logloss: 0.680047\n",
      "[92]\tvalid_0's binary_logloss: 0.679968\n",
      "[93]\tvalid_0's binary_logloss: 0.679905\n",
      "[94]\tvalid_0's binary_logloss: 0.679846\n",
      "[95]\tvalid_0's binary_logloss: 0.679798\n",
      "[96]\tvalid_0's binary_logloss: 0.679749\n",
      "[97]\tvalid_0's binary_logloss: 0.679689\n",
      "[98]\tvalid_0's binary_logloss: 0.679626\n",
      "[99]\tvalid_0's binary_logloss: 0.679572\n",
      "[100]\tvalid_0's binary_logloss: 0.679524\n",
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692349\n",
      "[2]\tvalid_0's binary_logloss: 0.691703\n",
      "[3]\tvalid_0's binary_logloss: 0.691119\n",
      "[4]\tvalid_0's binary_logloss: 0.690631\n",
      "[5]\tvalid_0's binary_logloss: 0.690183\n",
      "[6]\tvalid_0's binary_logloss: 0.689833\n",
      "[7]\tvalid_0's binary_logloss: 0.689487\n",
      "[8]\tvalid_0's binary_logloss: 0.689171\n",
      "[9]\tvalid_0's binary_logloss: 0.688899\n",
      "[10]\tvalid_0's binary_logloss: 0.688651\n",
      "[11]\tvalid_0's binary_logloss: 0.688361\n",
      "[12]\tvalid_0's binary_logloss: 0.688143\n",
      "[13]\tvalid_0's binary_logloss: 0.687936\n",
      "[14]\tvalid_0's binary_logloss: 0.68771\n",
      "[15]\tvalid_0's binary_logloss: 0.687537\n",
      "[16]\tvalid_0's binary_logloss: 0.687351\n",
      "[17]\tvalid_0's binary_logloss: 0.687171\n",
      "[18]\tvalid_0's binary_logloss: 0.687019\n",
      "[19]\tvalid_0's binary_logloss: 0.686835\n",
      "[20]\tvalid_0's binary_logloss: 0.686686\n",
      "[21]\tvalid_0's binary_logloss: 0.686528\n",
      "[22]\tvalid_0's binary_logloss: 0.686403\n",
      "[23]\tvalid_0's binary_logloss: 0.686278\n",
      "[24]\tvalid_0's binary_logloss: 0.686162\n",
      "[25]\tvalid_0's binary_logloss: 0.686041\n",
      "[26]\tvalid_0's binary_logloss: 0.685907\n",
      "[27]\tvalid_0's binary_logloss: 0.685793\n",
      "[28]\tvalid_0's binary_logloss: 0.685687\n",
      "[29]\tvalid_0's binary_logloss: 0.685578\n",
      "[30]\tvalid_0's binary_logloss: 0.685475\n",
      "[31]\tvalid_0's binary_logloss: 0.685363\n",
      "[32]\tvalid_0's binary_logloss: 0.685251\n",
      "[33]\tvalid_0's binary_logloss: 0.685168\n",
      "[34]\tvalid_0's binary_logloss: 0.685095\n",
      "[35]\tvalid_0's binary_logloss: 0.684985\n",
      "[36]\tvalid_0's binary_logloss: 0.684874\n",
      "[37]\tvalid_0's binary_logloss: 0.684763\n",
      "[38]\tvalid_0's binary_logloss: 0.684673\n",
      "[39]\tvalid_0's binary_logloss: 0.684574\n",
      "[40]\tvalid_0's binary_logloss: 0.684471\n",
      "[41]\tvalid_0's binary_logloss: 0.684389\n",
      "[42]\tvalid_0's binary_logloss: 0.684296\n",
      "[43]\tvalid_0's binary_logloss: 0.684215\n",
      "[44]\tvalid_0's binary_logloss: 0.684128\n",
      "[45]\tvalid_0's binary_logloss: 0.684063\n",
      "[46]\tvalid_0's binary_logloss: 0.683974\n",
      "[47]\tvalid_0's binary_logloss: 0.683888\n",
      "[48]\tvalid_0's binary_logloss: 0.6838\n",
      "[49]\tvalid_0's binary_logloss: 0.683737\n",
      "[50]\tvalid_0's binary_logloss: 0.683658\n",
      "[51]\tvalid_0's binary_logloss: 0.683597\n",
      "[52]\tvalid_0's binary_logloss: 0.683526\n",
      "[53]\tvalid_0's binary_logloss: 0.683447\n",
      "[54]\tvalid_0's binary_logloss: 0.683383\n",
      "[55]\tvalid_0's binary_logloss: 0.683293\n",
      "[56]\tvalid_0's binary_logloss: 0.683204\n",
      "[57]\tvalid_0's binary_logloss: 0.683131\n",
      "[58]\tvalid_0's binary_logloss: 0.68305\n",
      "[59]\tvalid_0's binary_logloss: 0.682976\n",
      "[60]\tvalid_0's binary_logloss: 0.682903\n",
      "[61]\tvalid_0's binary_logloss: 0.68282\n",
      "[62]\tvalid_0's binary_logloss: 0.682746\n",
      "[63]\tvalid_0's binary_logloss: 0.68269\n",
      "[64]\tvalid_0's binary_logloss: 0.68262\n",
      "[65]\tvalid_0's binary_logloss: 0.68256\n",
      "[66]\tvalid_0's binary_logloss: 0.682492\n",
      "[67]\tvalid_0's binary_logloss: 0.682415\n",
      "[68]\tvalid_0's binary_logloss: 0.68233\n",
      "[69]\tvalid_0's binary_logloss: 0.682272\n",
      "[70]\tvalid_0's binary_logloss: 0.682189\n",
      "[71]\tvalid_0's binary_logloss: 0.682126\n",
      "[72]\tvalid_0's binary_logloss: 0.682035\n",
      "[73]\tvalid_0's binary_logloss: 0.681962\n",
      "[74]\tvalid_0's binary_logloss: 0.681883\n",
      "[75]\tvalid_0's binary_logloss: 0.681823\n",
      "[76]\tvalid_0's binary_logloss: 0.681758\n",
      "[77]\tvalid_0's binary_logloss: 0.681679\n",
      "[78]\tvalid_0's binary_logloss: 0.681634\n",
      "[79]\tvalid_0's binary_logloss: 0.681567\n",
      "[80]\tvalid_0's binary_logloss: 0.681489\n",
      "[81]\tvalid_0's binary_logloss: 0.681421\n",
      "[82]\tvalid_0's binary_logloss: 0.681363\n",
      "[83]\tvalid_0's binary_logloss: 0.681318\n",
      "[84]\tvalid_0's binary_logloss: 0.681254\n",
      "[85]\tvalid_0's binary_logloss: 0.68119\n",
      "[86]\tvalid_0's binary_logloss: 0.681136\n",
      "[87]\tvalid_0's binary_logloss: 0.681086\n",
      "[88]\tvalid_0's binary_logloss: 0.68103\n",
      "[89]\tvalid_0's binary_logloss: 0.680979\n",
      "[90]\tvalid_0's binary_logloss: 0.680921\n",
      "[91]\tvalid_0's binary_logloss: 0.680861\n",
      "[92]\tvalid_0's binary_logloss: 0.680796\n",
      "[93]\tvalid_0's binary_logloss: 0.680729\n",
      "[94]\tvalid_0's binary_logloss: 0.680677\n",
      "[95]\tvalid_0's binary_logloss: 0.680633\n",
      "[96]\tvalid_0's binary_logloss: 0.68057\n",
      "[97]\tvalid_0's binary_logloss: 0.680516\n",
      "[98]\tvalid_0's binary_logloss: 0.680459\n",
      "[99]\tvalid_0's binary_logloss: 0.680409\n",
      "[100]\tvalid_0's binary_logloss: 0.680352\n",
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692467\n",
      "[2]\tvalid_0's binary_logloss: 0.691926\n",
      "[3]\tvalid_0's binary_logloss: 0.691429\n",
      "[4]\tvalid_0's binary_logloss: 0.690986\n",
      "[5]\tvalid_0's binary_logloss: 0.690602\n",
      "[6]\tvalid_0's binary_logloss: 0.690273\n",
      "[7]\tvalid_0's binary_logloss: 0.689952\n",
      "[8]\tvalid_0's binary_logloss: 0.689644\n",
      "[9]\tvalid_0's binary_logloss: 0.689404\n",
      "[10]\tvalid_0's binary_logloss: 0.689169\n",
      "[11]\tvalid_0's binary_logloss: 0.688943\n",
      "[12]\tvalid_0's binary_logloss: 0.688722\n",
      "[13]\tvalid_0's binary_logloss: 0.688532\n",
      "[14]\tvalid_0's binary_logloss: 0.688321\n",
      "[15]\tvalid_0's binary_logloss: 0.688154\n",
      "[16]\tvalid_0's binary_logloss: 0.687979\n",
      "[17]\tvalid_0's binary_logloss: 0.687839\n",
      "[18]\tvalid_0's binary_logloss: 0.687682\n",
      "[19]\tvalid_0's binary_logloss: 0.687526\n",
      "[20]\tvalid_0's binary_logloss: 0.687398\n",
      "[21]\tvalid_0's binary_logloss: 0.687226\n",
      "[22]\tvalid_0's binary_logloss: 0.687118\n",
      "[23]\tvalid_0's binary_logloss: 0.687004\n",
      "[24]\tvalid_0's binary_logloss: 0.68689\n",
      "[25]\tvalid_0's binary_logloss: 0.686756\n",
      "[26]\tvalid_0's binary_logloss: 0.686658\n",
      "[27]\tvalid_0's binary_logloss: 0.686565\n",
      "[28]\tvalid_0's binary_logloss: 0.686453\n",
      "[29]\tvalid_0's binary_logloss: 0.686349\n",
      "[30]\tvalid_0's binary_logloss: 0.686252\n",
      "[31]\tvalid_0's binary_logloss: 0.686156\n",
      "[32]\tvalid_0's binary_logloss: 0.686049\n",
      "[33]\tvalid_0's binary_logloss: 0.685972\n",
      "[34]\tvalid_0's binary_logloss: 0.685868\n",
      "[35]\tvalid_0's binary_logloss: 0.68578\n",
      "[36]\tvalid_0's binary_logloss: 0.685673\n",
      "[37]\tvalid_0's binary_logloss: 0.685565\n",
      "[38]\tvalid_0's binary_logloss: 0.685482\n",
      "[39]\tvalid_0's binary_logloss: 0.685405\n",
      "[40]\tvalid_0's binary_logloss: 0.685341\n",
      "[41]\tvalid_0's binary_logloss: 0.685261\n",
      "[42]\tvalid_0's binary_logloss: 0.685167\n",
      "[43]\tvalid_0's binary_logloss: 0.685095\n",
      "[44]\tvalid_0's binary_logloss: 0.685024\n",
      "[45]\tvalid_0's binary_logloss: 0.684927\n",
      "[46]\tvalid_0's binary_logloss: 0.68483\n",
      "[47]\tvalid_0's binary_logloss: 0.684731\n",
      "[48]\tvalid_0's binary_logloss: 0.684652\n",
      "[49]\tvalid_0's binary_logloss: 0.684573\n",
      "[50]\tvalid_0's binary_logloss: 0.684491\n",
      "[51]\tvalid_0's binary_logloss: 0.684414\n",
      "[52]\tvalid_0's binary_logloss: 0.684352\n",
      "[53]\tvalid_0's binary_logloss: 0.684296\n",
      "[54]\tvalid_0's binary_logloss: 0.684225\n",
      "[55]\tvalid_0's binary_logloss: 0.684158\n",
      "[56]\tvalid_0's binary_logloss: 0.68408\n",
      "[57]\tvalid_0's binary_logloss: 0.684009\n",
      "[58]\tvalid_0's binary_logloss: 0.683925\n",
      "[59]\tvalid_0's binary_logloss: 0.683859\n",
      "[60]\tvalid_0's binary_logloss: 0.68379\n",
      "[61]\tvalid_0's binary_logloss: 0.683724\n",
      "[62]\tvalid_0's binary_logloss: 0.683662\n",
      "[63]\tvalid_0's binary_logloss: 0.683598\n",
      "[64]\tvalid_0's binary_logloss: 0.683515\n",
      "[65]\tvalid_0's binary_logloss: 0.683441\n",
      "[66]\tvalid_0's binary_logloss: 0.683377\n",
      "[67]\tvalid_0's binary_logloss: 0.683313\n",
      "[68]\tvalid_0's binary_logloss: 0.683255\n",
      "[69]\tvalid_0's binary_logloss: 0.683183\n",
      "[70]\tvalid_0's binary_logloss: 0.683125\n",
      "[71]\tvalid_0's binary_logloss: 0.68306\n",
      "[72]\tvalid_0's binary_logloss: 0.683005\n",
      "[73]\tvalid_0's binary_logloss: 0.682944\n",
      "[74]\tvalid_0's binary_logloss: 0.682885\n",
      "[75]\tvalid_0's binary_logloss: 0.682833\n",
      "[76]\tvalid_0's binary_logloss: 0.682787\n",
      "[77]\tvalid_0's binary_logloss: 0.682722\n",
      "[78]\tvalid_0's binary_logloss: 0.682642\n",
      "[79]\tvalid_0's binary_logloss: 0.682575\n",
      "[80]\tvalid_0's binary_logloss: 0.682524\n",
      "[81]\tvalid_0's binary_logloss: 0.682472\n",
      "[82]\tvalid_0's binary_logloss: 0.682414\n",
      "[83]\tvalid_0's binary_logloss: 0.68237\n",
      "[84]\tvalid_0's binary_logloss: 0.682322\n",
      "[85]\tvalid_0's binary_logloss: 0.682279\n",
      "[86]\tvalid_0's binary_logloss: 0.682223\n",
      "[87]\tvalid_0's binary_logloss: 0.682151\n",
      "[88]\tvalid_0's binary_logloss: 0.682103\n",
      "[89]\tvalid_0's binary_logloss: 0.682048\n",
      "[90]\tvalid_0's binary_logloss: 0.68199\n",
      "[91]\tvalid_0's binary_logloss: 0.68194\n",
      "[92]\tvalid_0's binary_logloss: 0.681888\n",
      "[93]\tvalid_0's binary_logloss: 0.681841\n",
      "[94]\tvalid_0's binary_logloss: 0.681783\n",
      "[95]\tvalid_0's binary_logloss: 0.681725\n",
      "[96]\tvalid_0's binary_logloss: 0.681673\n",
      "[97]\tvalid_0's binary_logloss: 0.681622\n",
      "[98]\tvalid_0's binary_logloss: 0.681561\n",
      "[99]\tvalid_0's binary_logloss: 0.681508\n",
      "[100]\tvalid_0's binary_logloss: 0.681461\n",
      "2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.692475\n",
      "[2]\tvalid_0's binary_logloss: 0.691932\n",
      "[3]\tvalid_0's binary_logloss: 0.691415\n",
      "[4]\tvalid_0's binary_logloss: 0.691001\n",
      "[5]\tvalid_0's binary_logloss: 0.690632\n",
      "[6]\tvalid_0's binary_logloss: 0.690292\n",
      "[7]\tvalid_0's binary_logloss: 0.689963\n",
      "[8]\tvalid_0's binary_logloss: 0.689671\n",
      "[9]\tvalid_0's binary_logloss: 0.689366\n",
      "[10]\tvalid_0's binary_logloss: 0.689121\n",
      "[11]\tvalid_0's binary_logloss: 0.688911\n",
      "[12]\tvalid_0's binary_logloss: 0.688663\n",
      "[13]\tvalid_0's binary_logloss: 0.688472\n",
      "[14]\tvalid_0's binary_logloss: 0.688268\n",
      "[15]\tvalid_0's binary_logloss: 0.688071\n",
      "[16]\tvalid_0's binary_logloss: 0.687904\n",
      "[17]\tvalid_0's binary_logloss: 0.687739\n",
      "[18]\tvalid_0's binary_logloss: 0.687584\n",
      "[19]\tvalid_0's binary_logloss: 0.687454\n",
      "[20]\tvalid_0's binary_logloss: 0.687315\n",
      "[21]\tvalid_0's binary_logloss: 0.687181\n",
      "[22]\tvalid_0's binary_logloss: 0.687034\n",
      "[23]\tvalid_0's binary_logloss: 0.686893\n",
      "[24]\tvalid_0's binary_logloss: 0.686746\n",
      "[25]\tvalid_0's binary_logloss: 0.686569\n",
      "[26]\tvalid_0's binary_logloss: 0.686464\n",
      "[27]\tvalid_0's binary_logloss: 0.686349\n",
      "[28]\tvalid_0's binary_logloss: 0.686258\n",
      "[29]\tvalid_0's binary_logloss: 0.686156\n",
      "[30]\tvalid_0's binary_logloss: 0.686055\n",
      "[31]\tvalid_0's binary_logloss: 0.685944\n",
      "[32]\tvalid_0's binary_logloss: 0.685842\n",
      "[33]\tvalid_0's binary_logloss: 0.68575\n",
      "[34]\tvalid_0's binary_logloss: 0.685659\n",
      "[35]\tvalid_0's binary_logloss: 0.685548\n",
      "[36]\tvalid_0's binary_logloss: 0.685467\n",
      "[37]\tvalid_0's binary_logloss: 0.685388\n",
      "[38]\tvalid_0's binary_logloss: 0.685259\n",
      "[39]\tvalid_0's binary_logloss: 0.685159\n",
      "[40]\tvalid_0's binary_logloss: 0.685094\n",
      "[41]\tvalid_0's binary_logloss: 0.68499\n",
      "[42]\tvalid_0's binary_logloss: 0.684909\n",
      "[43]\tvalid_0's binary_logloss: 0.684813\n",
      "[44]\tvalid_0's binary_logloss: 0.684727\n",
      "[45]\tvalid_0's binary_logloss: 0.684636\n",
      "[46]\tvalid_0's binary_logloss: 0.684569\n",
      "[47]\tvalid_0's binary_logloss: 0.684482\n",
      "[48]\tvalid_0's binary_logloss: 0.684394\n",
      "[49]\tvalid_0's binary_logloss: 0.684321\n",
      "[50]\tvalid_0's binary_logloss: 0.684255\n",
      "[51]\tvalid_0's binary_logloss: 0.684176\n",
      "[52]\tvalid_0's binary_logloss: 0.6841\n",
      "[53]\tvalid_0's binary_logloss: 0.684046\n",
      "[54]\tvalid_0's binary_logloss: 0.683937\n",
      "[55]\tvalid_0's binary_logloss: 0.683881\n",
      "[56]\tvalid_0's binary_logloss: 0.683819\n",
      "[57]\tvalid_0's binary_logloss: 0.683741\n",
      "[58]\tvalid_0's binary_logloss: 0.683659\n",
      "[59]\tvalid_0's binary_logloss: 0.683587\n",
      "[60]\tvalid_0's binary_logloss: 0.683511\n",
      "[61]\tvalid_0's binary_logloss: 0.683453\n",
      "[62]\tvalid_0's binary_logloss: 0.683394\n",
      "[63]\tvalid_0's binary_logloss: 0.683317\n",
      "[64]\tvalid_0's binary_logloss: 0.683261\n",
      "[65]\tvalid_0's binary_logloss: 0.683194\n",
      "[66]\tvalid_0's binary_logloss: 0.683129\n",
      "[67]\tvalid_0's binary_logloss: 0.683074\n",
      "[68]\tvalid_0's binary_logloss: 0.682967\n",
      "[69]\tvalid_0's binary_logloss: 0.682912\n",
      "[70]\tvalid_0's binary_logloss: 0.682863\n",
      "[71]\tvalid_0's binary_logloss: 0.682792\n",
      "[72]\tvalid_0's binary_logloss: 0.682717\n",
      "[73]\tvalid_0's binary_logloss: 0.682662\n",
      "[74]\tvalid_0's binary_logloss: 0.682599\n",
      "[75]\tvalid_0's binary_logloss: 0.682543\n",
      "[76]\tvalid_0's binary_logloss: 0.682483\n",
      "[77]\tvalid_0's binary_logloss: 0.68244\n",
      "[78]\tvalid_0's binary_logloss: 0.68236\n",
      "[79]\tvalid_0's binary_logloss: 0.682262\n",
      "[80]\tvalid_0's binary_logloss: 0.6822\n",
      "[81]\tvalid_0's binary_logloss: 0.682146\n",
      "[82]\tvalid_0's binary_logloss: 0.682103\n",
      "[83]\tvalid_0's binary_logloss: 0.682048\n",
      "[84]\tvalid_0's binary_logloss: 0.68199\n",
      "[85]\tvalid_0's binary_logloss: 0.681934\n",
      "[86]\tvalid_0's binary_logloss: 0.681884\n",
      "[87]\tvalid_0's binary_logloss: 0.681825\n",
      "[88]\tvalid_0's binary_logloss: 0.681747\n",
      "[89]\tvalid_0's binary_logloss: 0.68169\n",
      "[90]\tvalid_0's binary_logloss: 0.681626\n",
      "[91]\tvalid_0's binary_logloss: 0.681569\n",
      "[92]\tvalid_0's binary_logloss: 0.681515\n",
      "[93]\tvalid_0's binary_logloss: 0.681466\n",
      "[94]\tvalid_0's binary_logloss: 0.681408\n",
      "[95]\tvalid_0's binary_logloss: 0.681354\n",
      "[96]\tvalid_0's binary_logloss: 0.681311\n",
      "[97]\tvalid_0's binary_logloss: 0.681254\n",
      "[98]\tvalid_0's binary_logloss: 0.681158\n",
      "[99]\tvalid_0's binary_logloss: 0.681098\n",
      "[100]\tvalid_0's binary_logloss: 0.681024\n"
     ]
    },
    {
     "data": {
      "text/plain": "            000001.SZ  000002.SZ  000004.SZ  000005.SZ  000008.SZ  000009.SZ  \\\ndt                                                                             \n2018-01-02   0.493846   0.444707   0.607680   0.465254   0.471888   0.522898   \n2018-01-03   0.478124   0.474631   0.466554   0.429369   0.523186   0.519098   \n2018-01-04   0.470652   0.449117   0.504040   0.472498   0.507653   0.459414   \n2018-01-05   0.450209   0.461409   0.515412   0.452461   0.559107   0.455729   \n2018-01-08   0.490038   0.475742   0.522390   0.433434   0.512971   0.466106   \n\n            000010.SZ  000011.SZ  000012.SZ  000014.SZ  ...  688306.SH  \\\ndt                                                      ...              \n2018-01-02   0.452501   0.522979   0.459546   0.499655  ...        NaN   \n2018-01-03   0.447803   0.507770   0.446901   0.529041  ...        NaN   \n2018-01-04   0.492937   0.534335   0.434041   0.532940  ...        NaN   \n2018-01-05   0.455199   0.488204   0.496707        NaN  ...        NaN   \n2018-01-08        NaN   0.422902   0.495050        NaN  ...        NaN   \n\n            301237.SZ  688197.SH  603209.SH  301226.SZ  603051.SH  301102.SZ  \\\ndt                                                                             \n2018-01-02        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-03        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-04        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-05        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-08        NaN        NaN        NaN        NaN        NaN        NaN   \n\n            301216.SZ  301258.SZ  301263.SZ  \ndt                                           \n2018-01-02        NaN        NaN        NaN  \n2018-01-03        NaN        NaN        NaN  \n2018-01-04        NaN        NaN        NaN  \n2018-01-05        NaN        NaN        NaN  \n2018-01-08        NaN        NaN        NaN  \n\n[5 rows x 4707 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000001.SZ</th>\n      <th>000002.SZ</th>\n      <th>000004.SZ</th>\n      <th>000005.SZ</th>\n      <th>000008.SZ</th>\n      <th>000009.SZ</th>\n      <th>000010.SZ</th>\n      <th>000011.SZ</th>\n      <th>000012.SZ</th>\n      <th>000014.SZ</th>\n      <th>...</th>\n      <th>688306.SH</th>\n      <th>301237.SZ</th>\n      <th>688197.SH</th>\n      <th>603209.SH</th>\n      <th>301226.SZ</th>\n      <th>603051.SH</th>\n      <th>301102.SZ</th>\n      <th>301216.SZ</th>\n      <th>301258.SZ</th>\n      <th>301263.SZ</th>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-02</th>\n      <td>0.493846</td>\n      <td>0.444707</td>\n      <td>0.607680</td>\n      <td>0.465254</td>\n      <td>0.471888</td>\n      <td>0.522898</td>\n      <td>0.452501</td>\n      <td>0.522979</td>\n      <td>0.459546</td>\n      <td>0.499655</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-03</th>\n      <td>0.478124</td>\n      <td>0.474631</td>\n      <td>0.466554</td>\n      <td>0.429369</td>\n      <td>0.523186</td>\n      <td>0.519098</td>\n      <td>0.447803</td>\n      <td>0.507770</td>\n      <td>0.446901</td>\n      <td>0.529041</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-04</th>\n      <td>0.470652</td>\n      <td>0.449117</td>\n      <td>0.504040</td>\n      <td>0.472498</td>\n      <td>0.507653</td>\n      <td>0.459414</td>\n      <td>0.492937</td>\n      <td>0.534335</td>\n      <td>0.434041</td>\n      <td>0.532940</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-05</th>\n      <td>0.450209</td>\n      <td>0.461409</td>\n      <td>0.515412</td>\n      <td>0.452461</td>\n      <td>0.559107</td>\n      <td>0.455729</td>\n      <td>0.455199</td>\n      <td>0.488204</td>\n      <td>0.496707</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-08</th>\n      <td>0.490038</td>\n      <td>0.475742</td>\n      <td>0.522390</td>\n      <td>0.433434</td>\n      <td>0.512971</td>\n      <td>0.466106</td>\n      <td>NaN</td>\n      <td>0.422902</td>\n      <td>0.495050</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 4707 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "year_list = [i for i in range(2018, 2024)]\n",
    "for year in year_list:\n",
    "    print(year)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in [3, 2, 1]:\n",
    "        factor_stack = pd.read_pickle(f\"./data/processed_data/factor_stack_{year - i}.pkl\").replace([np.inf, -np.inf], [0, 0])\n",
    "        stock_return = pd.read_pickle(f\"./data/processed_data/quantile_return_{year - i}.pkl\")\n",
    "        factor_stack = factor_stack.loc[stock_return.index, :]\n",
    "        X_train.append(factor_stack)\n",
    "        y_train.append(stock_return)\n",
    "    del factor_stack, stock_return\n",
    "    X_train = pd.concat(X_train)\n",
    "    y_train = pd.concat(y_train)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)\n",
    "    # model = TabNetClassifier()\n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train.values, y_train.values, eval_set=[(X_valid.values, y_valid.values)], early_stopping_rounds=200)\n",
    "    # model.save_model(f\"./log/tabnet/all_features/{year}\")\n",
    "    pd.to_pickle(model, f\"./log/lgbm/{year}.pkl\")\n",
    "    X_test = pd.read_pickle(f\"./data/processed_data/factor_stack_{year}.pkl\").replace([np.inf, -np.inf], [0, 0])\n",
    "    y_test = pd.read_pickle(f\"./data/processed_data/quantile_return_{year}.pkl\")\n",
    "    X_test = X_test.loc[y_test.index, :]\n",
    "    pred = model.predict_proba(X_test.values)[:, 1]\n",
    "    pred = pd.Series(pred, X_test.index).unstack()\n",
    "    score.append(pred)\n",
    "\n",
    "score = pd.concat(score)\n",
    "score.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "E:\\Anaconda\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "            000001.SZ  000002.SZ  000004.SZ  000005.SZ  000008.SZ  000009.SZ  \\\ndt                                                                             \n2018-01-02   0.450708   0.489603   0.426504   0.420520   0.509872   0.756832   \n2018-01-03   0.438138   0.518821   0.394988   0.418144   0.620185   0.678303   \n2018-01-04   0.450056   0.347225   0.375550   0.430921   0.640478   0.612415   \n2018-01-05   0.361006   0.374675   0.416526   0.417695   0.630809   0.710633   \n2018-01-08   0.373535   0.608893   0.460506   0.426929   0.650960   0.775479   \n\n            000010.SZ  000011.SZ  000012.SZ  000014.SZ  ...  688306.SH  \\\ndt                                                      ...              \n2018-01-02   0.435362   0.396833   0.252163   0.689781  ...        NaN   \n2018-01-03   0.402919   0.409570   0.507633   0.673246  ...        NaN   \n2018-01-04   0.451481   0.421166   0.259603   0.671142  ...        NaN   \n2018-01-05   0.378134   0.333742   0.360839        NaN  ...        NaN   \n2018-01-08        NaN   0.316277   0.507321        NaN  ...        NaN   \n\n            301237.SZ  688197.SH  603209.SH  301226.SZ  603051.SH  301102.SZ  \\\ndt                                                                             \n2018-01-02        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-03        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-04        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-05        NaN        NaN        NaN        NaN        NaN        NaN   \n2018-01-08        NaN        NaN        NaN        NaN        NaN        NaN   \n\n            301216.SZ  301258.SZ  301263.SZ  \ndt                                           \n2018-01-02        NaN        NaN        NaN  \n2018-01-03        NaN        NaN        NaN  \n2018-01-04        NaN        NaN        NaN  \n2018-01-05        NaN        NaN        NaN  \n2018-01-08        NaN        NaN        NaN  \n\n[5 rows x 4707 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000001.SZ</th>\n      <th>000002.SZ</th>\n      <th>000004.SZ</th>\n      <th>000005.SZ</th>\n      <th>000008.SZ</th>\n      <th>000009.SZ</th>\n      <th>000010.SZ</th>\n      <th>000011.SZ</th>\n      <th>000012.SZ</th>\n      <th>000014.SZ</th>\n      <th>...</th>\n      <th>688306.SH</th>\n      <th>301237.SZ</th>\n      <th>688197.SH</th>\n      <th>603209.SH</th>\n      <th>301226.SZ</th>\n      <th>603051.SH</th>\n      <th>301102.SZ</th>\n      <th>301216.SZ</th>\n      <th>301258.SZ</th>\n      <th>301263.SZ</th>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-02</th>\n      <td>0.450708</td>\n      <td>0.489603</td>\n      <td>0.426504</td>\n      <td>0.420520</td>\n      <td>0.509872</td>\n      <td>0.756832</td>\n      <td>0.435362</td>\n      <td>0.396833</td>\n      <td>0.252163</td>\n      <td>0.689781</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-03</th>\n      <td>0.438138</td>\n      <td>0.518821</td>\n      <td>0.394988</td>\n      <td>0.418144</td>\n      <td>0.620185</td>\n      <td>0.678303</td>\n      <td>0.402919</td>\n      <td>0.409570</td>\n      <td>0.507633</td>\n      <td>0.673246</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-04</th>\n      <td>0.450056</td>\n      <td>0.347225</td>\n      <td>0.375550</td>\n      <td>0.430921</td>\n      <td>0.640478</td>\n      <td>0.612415</td>\n      <td>0.451481</td>\n      <td>0.421166</td>\n      <td>0.259603</td>\n      <td>0.671142</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-05</th>\n      <td>0.361006</td>\n      <td>0.374675</td>\n      <td>0.416526</td>\n      <td>0.417695</td>\n      <td>0.630809</td>\n      <td>0.710633</td>\n      <td>0.378134</td>\n      <td>0.333742</td>\n      <td>0.360839</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-08</th>\n      <td>0.373535</td>\n      <td>0.608893</td>\n      <td>0.460506</td>\n      <td>0.426929</td>\n      <td>0.650960</td>\n      <td>0.775479</td>\n      <td>NaN</td>\n      <td>0.316277</td>\n      <td>0.507321</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 4707 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "year_list = [i for i in range(2018, 2024)]\n",
    "for year in year_list:\n",
    "    model.load_model(f\"./log/tabnet/all_features/{year}.zip\")\n",
    "    X_test = pd.read_pickle(f\"./data/processed_data/factor_stack_{year}.pkl\").replace([np.inf, -np.inf], [0, 0])\n",
    "    y_test = pd.read_pickle(f\"./data/processed_data/quantile_return_{year}.pkl\")\n",
    "    X_test = X_test.loc[y_test.index, :]\n",
    "    pred = model.predict_proba(X_test.values)[:, 1]\n",
    "    pred = pd.Series(pred, X_test.index).unstack()\n",
    "    score.append(pred)\n",
    "score = pd.concat(score)\n",
    "score.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "score.to_pickle(\"./data/score/score_lgbm.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
